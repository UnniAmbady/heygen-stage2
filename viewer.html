<!doctype html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/>
    <title>AI Avatar Viewer (Direct WebRTC + Audio)</title>
    <style>
      html,body{margin:0;padding:0;height:100%;width:100%;background:#0b0b0c;color:#eaeaea;font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
      .wrap{display:flex;flex-direction:column;gap:10px;width:100%;height:100%;align-items:center;justify-content:flex-start}
      .title{font-size:16px;text-align:center;margin-top:6px;opacity:.9}
      .stage{position:relative;width:100%;max-width:420px;aspect-ratio:9/16;background:#111;border-radius:18px;overflow:hidden;border:1px solid #222;display:grid;place-items:center}
      video{width:100%;height:100%;object-fit:cover;display:block}
      .status{font-size:12px;opacity:.85}
      .overlay{
        position:absolute; inset:0; display:flex; align-items:center; justify-content:center;
        background:rgba(0,0,0,0.35); backdrop-filter:saturate(1.1) blur(1px);
      }
      .overlay button{
        border:none; border-radius:999px; padding:14px 18px; font-size:14px; cursor:pointer;
        box-shadow:0 8px 22px rgba(0,0,0,.35);
      }
    </style>
  </head>
  <body>
    <div class="wrap">
      <div class="title">Avatar: <span id="aname"></span></div>
      <div class="stage">
        <!-- Video shows picture only; audio routed to dedicated <audio> element -->
        <video id="video" playsinline autoplay muted></video>
        <div class="overlay" id="audioGate" style="display:flex">
          <button id="enableBtn">ðŸ”Š Tap to enable sound</button>
        </div>
      </div>
      <div class="status" id="status">initializingâ€¦</div>
    </div>

    <audio id="audio" autoplay></audio>

    <script>
      // Injected by Streamlit
      const SESSION_TOKEN = "__SESSION_TOKEN__";
      const AVATAR_NAME   = "__AVATAR_NAME__";
      const SESSION_ID    = "__SESSION_ID__";
      const OFFER_SDP     = "__OFFER_SDP__";          // raw text from API
      const RTC_CONFIG    = __RTC_CONFIG__ || {};     // {"iceServers":[...]}
      document.getElementById("aname").textContent = AVATAR_NAME;

      const statusEl = document.getElementById("status");
      const setStatus = (t)=> statusEl.textContent = t;

      // ---- DIRECT WEBRTC (no SDK) ----
      const pc = new RTCPeerConnection(RTC_CONFIG);

      // Explicitly receive both audio and video
      try {
        pc.addTransceiver('audio', { direction: 'recvonly' });
        pc.addTransceiver('video', { direction: 'recvonly' });
      } catch {}

      const video = document.getElementById("video");
      const audio = document.getElementById("audio");
      const gate  = document.getElementById("audioGate");
      const btn   = document.getElementById("enableBtn");

      async function ensureAudio() {
        try {
          audio.muted = false;
          audio.volume = 1.0;
          await audio.play();
          gate.style.display = "none";
        } catch {
          gate.style.display = "flex";
        }
      }

      btn.addEventListener('click', async () => {
        try {
          audio.muted = false;
          audio.volume = 1.0;
          await audio.play();
          gate.style.display = "none";
        } catch {}
      });

      pc.ontrack = (ev) => {
        const [stream] = ev.streams;
        if (!stream) return;
        if (ev.track.kind === 'video') {
          video.srcObject = stream;
          video.muted = true;           // picture only
          video.play().catch(()=>{});
        } else if (ev.track.kind === 'audio') {
          audio.srcObject = stream;     // sound goes here
          setTimeout(ensureAudio, 100);
        }
      };

      pc.oniceconnectionstatechange = () => {
        if (pc.iceConnectionState === "connected" || pc.iceConnectionState === "completed") {
          setStatus("connected");
        } else if (pc.iceConnectionState === "failed" || pc.iceConnectionState === "disconnected") {
          setStatus("ice " + pc.iceConnectionState);
        }
      };

      (async () => {
        try {
          setStatus("applying offerâ€¦");
          await pc.setRemoteDescription({ type: "offer", sdp: OFFER_SDP });

          setStatus("creating answerâ€¦");
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);

          // Wait for ICE to finish gathering local candidates (same timing as your working file)
          await new Promise((resolve) => {
            if (pc.iceGatheringState === "complete") return resolve();
            const check = () => {
              if (pc.iceGatheringState === "complete") {
                pc.removeEventListener("icegatheringstatechange", check);
                resolve();
              }
            };
            pc.addEventListener("icegatheringstatechange", check);
            setTimeout(resolve, 1500);
          });

          setStatus("starting sessionâ€¦");
          await fetch("https://api.heygen.com/v1/streaming.start", {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${SESSION_TOKEN}`,
              "Content-Type": "application/json",
              "accept": "application/json"
            },
            body: JSON.stringify({
              session_id: SESSION_ID,
              sdp: { type: "answer", sdp: pc.localDescription.sdp }
            })
          });

          setStatus("waiting for mediaâ€¦");
          gate.style.display = "flex";  // show until audio is allowed

        } catch (err) {
          setStatus("init error");
          console.error(err);
        }
      })();
    </script>
  </body>
</html>
